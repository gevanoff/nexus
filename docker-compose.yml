version: '3.8'

services:
  # Gateway Service - Central API gateway
  gateway:
    build:
      context: ./services/gateway
      dockerfile: Dockerfile
    container_name: nexus-gateway
    ports:
      - "${GATEWAY_PORT:-8800}:8800"
      - "${OBSERVABILITY_PORT:-8801}:8801"
    environment:
      # Server configuration
      - GATEWAY_HOST=0.0.0.0
      - GATEWAY_PORT=8800
      - GATEWAY_BEARER_TOKEN=${GATEWAY_BEARER_TOKEN:-change-me-in-production}
      
      # Observability
      - OBSERVABILITY_HOST=0.0.0.0
      - OBSERVABILITY_PORT=8801
      - METRICS_ENABLED=true
      
      # Upstream services (using Docker service names)
      - OLLAMA_BASE_URL=http://ollama:11434
      - IMAGES_BACKEND=${IMAGES_BACKEND:-http_openai_images}
      - IMAGES_HTTP_BASE_URL=http://images:7860
      - AUDIO_BACKEND_URL=http://tts:9940
      
      # Routing configuration
      - DEFAULT_BACKEND=ollama
      - ROUTER_ENABLE_POLICY=true
      
      # Request limits
      - MAX_REQUEST_BYTES=10485760
      
      # Data persistence paths (inside container)
      - MEMORY_DB_PATH=/data/memory.sqlite
      - USER_DB_PATH=/data/users.sqlite
      - UI_IMAGE_DIR=/data/ui_images
      
      # Tool bus configuration
      - TOOLS_LOG_MODE=ndjson
      - TOOLS_LOG_PATH=/data/tools/invocations.jsonl
      
      # Memory v2
      - MEMORY_V2_ENABLED=true
    volumes:
      - gateway_data:/data
      - ./services/gateway/app:/app
    depends_on:
      - ollama
    networks:
      - nexus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8800/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama Service - LLM inference
  ollama:
    image: ollama/ollama:latest
    container_name: nexus-ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_MODELS=/root/.ollama/models
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - nexus
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Image Generation Service (InvokeAI)
  images:
    build:
      context: ./services/images
      dockerfile: Dockerfile
    container_name: nexus-images
    ports:
      - "${IMAGES_PORT:-7860}:7860"
    environment:
      - HOST=0.0.0.0
      - PORT=7860
      - INVOKEAI_ROOT=/data
    volumes:
      - images_data:/data
      - images_models:/data/models
    networks:
      - nexus
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    profiles:
      - full
      - images

  # TTS Service - Text-to-Speech
  tts:
    build:
      context: ./services/tts
      dockerfile: Dockerfile
    container_name: nexus-tts
    ports:
      - "${TTS_PORT:-9940}:9940"
    environment:
      - HOST=0.0.0.0
      - PORT=9940
    volumes:
      - tts_data:/data
    networks:
      - nexus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9940/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    profiles:
      - full
      - audio

networks:
  nexus:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  gateway_data:
    driver: local
  ollama_data:
    driver: local
  images_data:
    driver: local
  images_models:
    driver: local
  tts_data:
    driver: local
