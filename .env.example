# Nexus Configuration
# Copy this file to .env and customize for your environment

# ===== Gateway Configuration =====

# Gateway authentication token (required)
# Generate a strong random token for production
GATEWAY_BEARER_TOKEN=change-me-in-production

# Gateway ports
GATEWAY_PORT=8800
OBSERVABILITY_PORT=8801

# Gateway network binding (inside container)
GATEWAY_HOST=0.0.0.0
OBSERVABILITY_HOST=0.0.0.0

# Optional request guardrails
# MAX_REQUEST_BYTES=0 disables.
MAX_REQUEST_BYTES=10485760

# Optional: gateway-side allowlists (advanced)
IP_ALLOWLIST=
UI_IP_ALLOWLIST=

# Optional multi-token auth + per-token policies
GATEWAY_BEARER_TOKENS=
GATEWAY_TOKEN_POLICIES_JSON=
GATEWAY_TOKEN_POLICIES_STRICT=true

# ===== Service Ports =====

# LLM inference service
OLLAMA_PORT=11434

# Image generation service
IMAGES_PORT=7860

# Text-to-speech service
TTS_PORT=9940

# Service discovery (etcd)
ETCD_PORT=2379
ETCD_ENABLED=true
ETCD_URL=http://etcd:2379
ETCD_PREFIX=/nexus/services/
ETCD_POLL_INTERVAL=15
ETCD_SEED_FROM_ENV=true

# ===== Image Generation Backend =====

# Options: mock, http_openai_images, http_a1111
IMAGES_BACKEND=http_openai_images

# Images service (OpenAI Images shim)
# stub: returns a tiny PNG (no GPU/backends required)
# invokeai_queue: proxies to an InvokeAI instance via INVOKEAI_BASE_URL
IMAGES_SHIM_MODE=stub

# Only used when IMAGES_SHIM_MODE=invokeai_queue
INVOKEAI_BASE_URL=http://invokeai:9090

# ===== Resource Configuration =====

# Enable GPU support (requires NVIDIA Docker runtime)
# Set to 'false' to run CPU-only
ENABLE_GPU=true

# Memory limits (optional)
# GATEWAY_MEMORY_LIMIT=2g
# OLLAMA_MEMORY_LIMIT=8g
# IMAGES_MEMORY_LIMIT=16g

# ===== Service Profiles =====

# Docker Compose profiles to enable
# Default: Only gateway and ollama
# Options: full, images, audio
# 
# Examples:
#   COMPOSE_PROFILES=full          # All services
#   COMPOSE_PROFILES=images,audio  # Gateway + Ollama + Images + TTS
#
COMPOSE_PROFILES=

# ===== Advanced Configuration =====

# Enable/disable metrics collection
METRICS_ENABLED=true

# Router configuration
DEFAULT_BACKEND=ollama
ROUTER_ENABLE_POLICY=true

# Memory v2 features
MEMORY_V2_ENABLED=true

# ===== Tool Bus =====

# Tool bus logs (persisted under ./.runtime/gateway/data)
TOOLS_LOG_MODE=ndjson
TOOLS_LOG_PATH=/var/lib/gateway/data/tools/invocations.jsonl
TOOLS_LOG_DIR=/var/lib/gateway/data/tools

# Tools working directory (inside container)
TOOLS_SHELL_CWD=/var/lib/gateway/data/tools_work
TOOLS_SHELL_TIMEOUT_SEC=20

# External tools registry (persisted under ./.runtime/gateway/config)
TOOLS_REGISTRY_PATH=/var/lib/gateway/config/tools_registry.json
TOOLS_REGISTRY_SHA256=

# Safe defaults: keep high-privilege tools off
TOOLS_ALLOW_SHELL=false
TOOLS_ALLOW_FS=false
TOOLS_ALLOW_HTTP_FETCH=false
TOOLS_ALLOW_GIT=false
TOOLS_ALLOW_SYSTEM_INFO=false
TOOLS_ALLOW_MODELS_REFRESH=false
TOOLS_ALLOWLIST=echo,followyourcanvas_generate,heartmula_generate,lighton_ocr,skyreels_generate

# ===== Development Options =====

# Enable hot reload for gateway (development only)
# HOT_RELOAD=true

# Logging level
# LOG_LEVEL=INFO

# ===== Data Persistence =====

# Nexus uses host bind mounts under `./.runtime/` by default.
# - Gateway RW data:   ./.runtime/gateway/data   → /var/lib/gateway/data
# - Gateway RO config: ./.runtime/gateway/config → /var/lib/gateway/config
# - Ollama models:     ./.runtime/ollama         → /root/.ollama
# - Images:            ./.runtime/images/*       → /data
# - TTS:               ./.runtime/tts/data       → /data
# - etcd:              ./.runtime/etcd/data      → /etcd-data

# If you want to relocate persistence outside the repo (recommended for servers),
# update the bind-mount sources in the relevant `docker-compose.*.yml` file.



# ===== TTS (Pocket TTS shim) =====

# Backend selection: auto | python | command
POCKET_TTS_BACKEND=auto

# Default hints
POCKET_TTS_MODEL_NAME=pocket-tts
POCKET_TTS_MODEL_PATH=
POCKET_TTS_VOICE=alba

# Command backend (used when POCKET_TTS_BACKEND=command or when python import fails)
POCKET_TTS_COMMAND=pocket-tts
